% Encoding: UTF-8

@Article{SabiEtAl2016,
  author       = {Sabi, Humphrey M. and Uzoka, Faith-Michael E. and Langmia, Kehbuma and Njeh, Felix M.},
  title        = {Conceptualizing a model for adoption of cloud computing in education},
  journaltitle = {International Journal of Information Management},
  year         = {2016},
  volume       = {36},
  number       = {2},
  pages        = {183--191},
  doi          = {10.1016/j.ijinfomgt.2015.11.010},
  url          = {http://www.sciencedirect.com/science/article/pii/S0268401215001115},
}

@Online{LewisFowler2014,
  author    = {Lewis, James and Fowler, Martin},
  title     = {Microservices: a definition of this new architectural term},
  date      = {2014-03-25},
  url       = {http://martinfowler.com/articles/microservices.html},
  urldate   = {2016-09-01},
}

@Online{Hykes2013,
  author    = {Solomon Hykes},
  title     = {The future of Linux Containers (PyCon 2013)},
  date      = {2013-03-21},
  url       = {https://www.youtube.com/watch?v=wW9CAH9nSLs},
  urldate   = {2016-09-01},
}

@Thesis{Govaerts2022,
  author      = {Arne Govaerts},
  date        = {2022},
  institution = {HOGENT},
  title       = {Detecteren van elderspeak},
  type        = {bathesis},
}

@Thesis{Gussem2022,
  author      = {Sibian De Gussem},
  date        = {2022},
  institution = {HOGENT},
  title       = {Nursery Tone Monitor: detecteren van elderspeak via AI},
  type        = {bathesis},
}

@Thesis{Daems2023,
  author      = {Benjamin Daems},
  date        = {2023},
  institution = {HOGENT},
  title       = {Nursery Tone Monitor. Verbetering van elderspeech-detectie door middel van ruisonderdrukking en stilteherkenning},
  type        = {bathesis},
}

@Thesis{Coetsiers2024,
  author      = {Jens Coetsiers},
  date        = {2024},
  institution = {HOGENT},
  title       = {Transcriptie van één-op-één-gesprekken in Vlaamse spreektaal: Evaluatie van beschikbare STT-Systemen voor het Nederlands.},
  type        = {bathesis},
}

@Thesis{Schryver2024,
  author      = {Bianca De Schryver},
  date        = {2024},
  institution = {HOGENT},
  title       = {Whisper Spraak-naar-tekstmodel testen voor het monitoren van 'secondary babytalk' in de zorgverlening.},
  type        = {bathesis},
}

@Thesis{Branden2024,
  author      = {Ine Van den Branden},
  date        = {2024},
  institution = {HOGENT},
  title       = {Elderspeak Detector: tekstanalyse met behulp van AI voor het detecteren van 'Secondary Babytalk' in de zorgverlening.},
  type        = {bathesis},
}

@InProceedings{Nachmani2020,
  author    = {Nachmani, Eliya and Adi, Yossi and Wolf, Lior},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  date      = {2020},
  title     = {Voice Separation with an Unknown Number of Multiple Speakers},
  editor    = {III, Hal Daumé and Singh, Aarti},
  pages     = {7164--7175},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  url       = {https://proceedings.mlr.press/v119/nachmani20a.html},
  volume    = {119},
  abstract  = {We present a new method for separating a mixed audio sequence, in which multiple voices speak simultaneously. The new method employs gated neural networks that are trained to separate the voices at multiple processing steps, while maintaining the speaker in each output channel fixed. A different model is trained for every number of possible speakers, and the model with the largest number of speakers is employed to select the actual number of speakers in a given sample. Our method greatly outperforms the current state of the art, which, as we show, is not competitive for more than two speakers.},
  pdf       = {http://proceedings.mlr.press/v119/nachmani20a/nachmani20a.pdf},
}

@Article{Zeghidour2021,
  author       = {Zeghidour, Neil and Grangier, David},
  date         = {2021},
  journaltitle = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title        = {Wavesplit: End-to-End Speech Separation by Speaker Clustering},
  doi          = {10.1109/TASLP.2021.3099291},
  pages        = {2840-2849},
  volume       = {29},
  keywords     = {Training;Task analysis;Speech processing;Noise measurement;Convolution;Source separation;Benchmark testing;Artificial neural networks;source separation;speech enhancement},
}

@InBook{Nandal2019,
  author    = {Nandal, P.},
  booktitle = {Sustainable Communication Networks and Application},
  date      = {2019-11},
  title     = {Speech Separation Using Deep Learning},
  doi       = {10.1007/978-3-030-34515-0_34},
  isbn      = {9783030345150},
  pages     = {319--326},
  publisher = {Springer International Publishing},
  issn      = {2367-4520},
}

@InProceedings{Li2021,
  author    = {Li, Chenda and Luo, Yi and Han, Cong and Li, Jinyu and Yoshioka, Takuya and Zhou, Tianyan and Delcroix, Marc and Kinoshita, Keisuke and Boeddeker, Christoph and Qian, Yanmin and Watanabe, Shinji and Chen, Zhuo},
  booktitle = {2021 IEEE Spoken Language Technology Workshop (SLT)},
  title     = {Dual-Path RNN for Long Recording Speech Separation},
  doi       = {10.1109/SLT48900.2021.9383514},
  pages     = {865-872},
  keywords  = {Conferences;Task analysis;Cascading style sheets;Continuous speech separation;long recording speech separation;dual-path RNN},
  year      = {2021},
}

@Comment{jabref-meta: databaseType:biblatex;}
